# ğŸ§ª Molecular Solubility Prediction (ESOL Dataset)

This project predicts the **aqueous solubility of molecules** using different machine learning models.  
The dataset used is the **ESOL dataset**, which contains molecules with experimental solubility values.  

The goal is to evaluate multiple ML models (Linear Regression, Random Forest, XGBoost), perform **hyperparameter tuning**, and identify the best-performing model for solubility prediction.  

---

## ğŸ“‚ Project Structure

1. **Load and Import Dataset**  
2. **Data Splitting**  
3. **Linear Regression**  
   - Predictions and Metrics  
   - Predicted vs Actual Plot  
4. **Random Forest Regressor**  
   - Predictions and Metrics  
   - Predicted vs Actual Plot  
5. **XGBoost Model**  
   - Train XGBoost  
   - Predictions and Metrics  
   - Predicted vs Actual Plot  
6. **Model Comparison**  
   - RÂ² and MSE comparison plots  
7. **Hyperparameter Tuning for XGBoost**  
8. **Final XGBoost Model with Best Parameters**  
   - Predictions and Metrics  
   - Predicted vs Actual Plot  
9. **Baseline vs Tuned XGBoost Performance**  
   - Metrics comparison (table + plots)  
10. **Conclusion & Future Work**  

---

## âš™ï¸ Tech Stack

- **Python**
- **Scikit-learn** (Linear Regression, Random Forest, metrics, model selection)
- **XGBoost** (regression and tuning)
- **Matplotlib / Seaborn** (visualization)
- **Google Colab** (execution environment)

---

## ğŸ“Š Results

- **Linear Regression** â†’ Weak performance (negative RÂ²).  
- **Random Forest** â†’ Better than baseline, moderate performance.  
- **XGBoost** â†’ Outperformed other models.  
- **Tuned XGBoost** â†’ Achieved the **best RÂ² score** with optimized hyperparameters.  

Example metrics (fill with your values):  
| Model                   | RÂ² Score  |   MSE   |
|-------------------------|---------: |--------: |
| Linear Regression       |   -3.1    |   19.5   |
| Random Forest           |    0.86   |   0.63   |
| XGBoost (Baseline)      |    0.89   |   0.47   |
| XGBoost (Tuned)         |    0.88   |   0.53   |

---

## ğŸ“ˆ Visualizations

- **Predicted vs Actual plots** for each model.  
- **Model comparison bar charts** (RÂ², MSE).  
- **Baseline vs Tuned XGBoost plots** to highlight improvement.  

---

## ğŸš€ Future Work

- Try **Graph Neural Networks (GNNs)** for molecular property prediction.  
- Use **other chemical datasets** (LogP, FreeSolv, Lipophilicity).  
- Explore **deep learning approaches** with molecular fingerprints.  

---

## ğŸ‘©â€ğŸ’» Author

- Project by Priyanka.
